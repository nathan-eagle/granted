{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7fdf5cc",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e6eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('../grantedai')\n",
    "from chat_complete import chat_complete_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa67349a",
   "metadata": {},
   "source": [
    "# grab api key from cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7478e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.cloud import secretmanager\n",
    "\n",
    "project_id = 'python-backend-v1'\n",
    "client = secretmanager.SecretManagerServiceClient()\n",
    "name = f\"projects/{project_id}/secrets/OPENAI_API_KEY/versions/2\"\n",
    "response = client.access_secret_version(request={\"name\": name})\n",
    "my_secret_value = response.payload.data.decode(\"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21605a0",
   "metadata": {},
   "source": [
    "## define what an sbir section is: uid to find the prompt, number of user inputs, what to do with the output, and list of any user inputs that are cut/paste from previous runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d60a958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SbirSection:\n",
    "    def __init__(self, uid, num_q, result, replace_q = None):\n",
    "        self.uid = uid\n",
    "        self.num_q = num_q\n",
    "        self.result = result # True if the output goes in final sbir, False if its just for cut and paste\n",
    "        self.replace_q = replace_q  # which qinput is a cut and paste\n",
    "\n",
    "# this is the structure of the individual pages in the NIH - SBIR section\n",
    "# uid, number of inputs, what to call the output, dictionary of cut/paste\n",
    "specific_aims = SbirSection('1686931095568x127537042873881800', 2, \"Specific Aims\")\n",
    "concept_overview = SbirSection('1686931095582x126136176460591060', 5, \"Output\", {4 : \"Specific Aims\"})\n",
    "project_narrative = SbirSection('1686931095420x670283125425270500', 1, \"Output\")\n",
    "project_summary = SbirSection('1682951835439x155695279795943460', 1, \"Output\", {1: \"Specific Aims\"})\n",
    "personal_statement = SbirSection('1682951835365x179818839606519230', 5, \"Output\", {5: \"Specific Aims\"})\n",
    "contributions_to_science = SbirSection('1682951835291x143168345947523040', 4, \"Output\")\n",
    "\n",
    "\n",
    "# this is the collection of nih-sbir pages to be run in order\n",
    "nih_sbir = [specific_aims, concept_overview, project_narrative, project_summary, personal_statement, contributions_to_science]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d758ca",
   "metadata": {},
   "source": [
    "## these are all the user inputs from nih-sbir pages that are not cut/paste from previous outputs.  15 in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c6bcd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# these are the number of user input fields that would be required on an nih-sbir page\n",
    "qs = []\n",
    "\n",
    "# Specific aims\n",
    "qs.append(\"Leverage the unique capabilities of Aldatu’s qPCR-enabling PANDAA technology to mitigate lineage-associated genomic \\\n",
    "variability and develop a rapid, pan-lineage molecular assay for LASV detection\")\n",
    "qs.append(\"Design PANDAA-LASV primers and probes and optimize reactions.  \\\n",
    "      Refine PANDAA-LASV reagents on divergent genotypes.  \\\n",
    "      Validate PANDAA-LASV diagnostic prototype both analytically and clinically\")\n",
    "\n",
    "# Concept overview\n",
    "qs.append(\"The prevalence of Alzheimer's disease (AD) is rapidly increasing, affecting millions of people \\\n",
    "worldwide. Current diagnostic methods for AD are invasive, expensive, and often inaccurate, leading to \\\n",
    "delayed or missed diagnoses.\")\n",
    "\n",
    "qs.append(\"Early and accurate diagnosis of AD is crucial for timely intervention and treatment, \\\n",
    "which can significantly improve patients' quality of life and reduce healthcare costs. Developing a \\\n",
    "non-invasive, cost-effective, and accurate diagnostic tool for AD would greatly benefit patients, \\\n",
    "caregivers, and healthcare providers.\")\n",
    "\n",
    "qs.append(\"Our team has developed a novel artificial intelligence (AI)-based system that analyzes speech patterns and \\\n",
    "linguistic markers to detect early signs of AD. This innovative approach leverages machine learning algorithms and \\\n",
    "natural language processing techniques to identify subtle changes in speech and language that are indicative of \\\n",
    "cognitive decline.\")\n",
    "\n",
    "qs.append(\"The primary target users of our AI-based diagnostic tool are healthcare providers, \\\n",
    "including neurologists, geriatricians, and primary care physicians. Additionally, our solution \\\n",
    "could be integrated into telemedicine platforms, enabling remote monitoring and assessment of \\\n",
    "patients at risk for AD. The potential market for our technology includes hospitals, clinics, and \\\n",
    "long-term care facilities, as well as pharmaceutical companies and research institutions involved in \\\n",
    "AD research and drug development.\")\n",
    "\n",
    "# Project narrative\n",
    "qs.append(\"Developing AI-based tool that analyzes speech patterns for early signs of AD.  Should be used by clinicians \\\n",
    "to improve patient outcomes.\")\n",
    "\n",
    "# Personal statement\n",
    "qs.append(\"PI\")\n",
    "qs.append(\"Early-stage investigator\")\n",
    "qs.append(\"MacArthur genius grant recipient\")\n",
    "qs.append(\"Trustworthy AI systems, clinical tools\")\n",
    "\n",
    "# Contributions to science\n",
    "qs.append(\"Background: Around the world, populations are aging and there is a growing concern about ways that \\\n",
    "older adults can maintain their health and well-being while living in their homes. \\\n",
    "Objectives: The aim of this paper was to conduct a systematic literature review to determine: (1) the \\\n",
    "levels of technology readiness among older adults and, (2) evidence for smart homes and home-based \\\n",
    "health-monitoring technologies that support aging in place for older adults who have complex needs. \\\n",
    "Results: We identified and analyzed 48 of 1863 relevant papers. Our analyses found that: (1) technologyreadiness level for smart homes and home health monitoring technologies is low; (2) the highest level of \\\n",
    "evidence is 1b (i.e., one randomized controlled trial with a PEDro score ≥6); smart homes and home health \\\n",
    "monitoring technologies are used to monitor activities of daily living, cognitive decline and mental health, \\\n",
    "and heart conditions in older adults with complex needs; (3) there is no evidence that smart homes and\\\n",
    "home health monitoring technologies help address disability prediction and health-related quality of life,\\\n",
    "or fall prevention; and (4) there is conflicting evidence that smart homes and home health monitoring\\\n",
    "technologies help address chronic obstructive pulmonary disease.\\\n",
    "Conclusions: The level oftechnology readiness for smart homes and home health monitoring technologies\\\n",
    "is still low. The highest level of evidence found was in a study that supported home health technologies\\\n",
    "for use in monitoring activities of daily living, cognitive decline, mental health, and heart conditions in\\\n",
    "older adults with complex needs.\")\n",
    "qs.append(\"\")\n",
    "qs.append(\"\")\n",
    "qs.append(\"\")\n",
    "          \n",
    "# this is the information that needs to be sent from the page to the sbir function\n",
    "page_data = {}\n",
    "page_data['email'] = \"brian3000@gmail.com\"\n",
    "page_data['branch'] = '35zp'\n",
    "page_data['prompt_header'] = '''\n",
    "[Applicant Summary]: No information provided\n",
    "[Agency Summary]:No information provided\n",
    "[RFP Summary]: No information provided\n",
    "'''\n",
    "page_data['model_title'] = \"Humor\"\n",
    "page_data['project_id'] = \"1683121929445x949068210706579500\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e67b6c",
   "metadata": {},
   "source": [
    "## this code will live in google cloud function as the sbir_single_shot\n",
    "## for each page we look up the prompt, pop off user inputs or cut/paste, send to \n",
    "## gpt4, and store the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc61668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "scratchpad = {}\n",
    "counter = 0\n",
    "for page in nih_sbir:\n",
    "    uid = page.uid\n",
    "    url = 'https://grantedai.com/version-'+page_data['branch']+'/api/1.1/obj/model/' + uid\n",
    "    x = requests.get(url)\n",
    "    model_data = x.json()['response']\n",
    "    \n",
    "    # construct body from model_data and project_data\n",
    "    body = \"\"\n",
    "    if model_data['include_header']: body += page_data['prompt_header']\n",
    "    body += model_data['prompt']\n",
    "    for i in range(1,page.num_q+1):\n",
    "        if page.replace_q and i in page.replace_q.keys():\n",
    "            body = body.replace(\"q%dinput\" % i,scratchpad[page.replace_q[i]])\n",
    "        else: \n",
    "            q = qs.pop(0)\n",
    "            body = body.replace(\"q%dinput\" % i,q)\n",
    "                              \n",
    "    # Data to be sent\n",
    "    data = {\n",
    "        \"email\": page_data['email'],\n",
    "        \"branch\": page_data['branch'],\n",
    "        \"debug\": \"True\",\n",
    "        \"body\" : body,\n",
    "        \"model_title\": page_data['model_title'],\n",
    "        \"project_id\": page_data['project_id']\n",
    "      }\n",
    "\n",
    "    response = chat_complete_openai(data, my_secret_value)\n",
    "    text = response['text']\n",
    "    if page.result not in scratchpad.keys():\n",
    "        scratchpad[page.result] = \"\"\n",
    "    scratchpad[page.result] += text + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a710dd0f",
   "metadata": {},
   "source": [
    "## this is what all of the output concatenated together look like.  we'll need some additional formatting presumably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a1a017",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import bbcode\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def display_bbcode(bbcode_string):\n",
    "    parser = bbcode.Parser()\n",
    "    html_string = parser.format(bbcode_string)\n",
    "    display(HTML(html_string))\n",
    "\n",
    "# usage\n",
    "display_bbcode(scratchpad['Output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74799816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
